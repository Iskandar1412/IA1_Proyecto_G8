{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNE4hAUQmZCawMIu2YTyD/n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HyNlT7WUOUo7","outputId":"af6440f8-7692-4cac-ab69-dbbce42c53d5","executionInfo":{"status":"ok","timestamp":1735819462853,"user_tz":360,"elapsed":8330373,"user":{"displayName":"Camilo Ernesto Sincal Sipac","userId":"00229629946990659316"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional_12\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_20            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ input_layer_21            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding_16 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m262,144\u001b[0m │ input_layer_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ not_equal_16 (\u001b[38;5;33mNotEqual\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding_17 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m194,304\u001b[0m │ input_layer_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)            │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │        \u001b[38;5;34m525,312\u001b[0m │ embedding_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n","│                           │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]     │                │ not_equal_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)            │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m525,312\u001b[0m │ embedding_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n","│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],         │\n","│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │ lstm_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]          │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m759\u001b[0m)      │        \u001b[38;5;34m195,063\u001b[0m │ lstm_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_20            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ input_layer_21            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ input_layer_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ not_equal_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">194,304</span> │ input_layer_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n","│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]     │                │ not_equal_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n","│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],         │\n","│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │ lstm_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]          │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">759</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195,063</span> │ lstm_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,702,135\u001b[0m (6.49 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,702,135</span> (6.49 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,702,135\u001b[0m (6.49 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,702,135</span> (6.49 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","   1586/Unknown \u001b[1m521s\u001b[0m 326ms/step - accuracy: 0.0596 - loss: 2.6504"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 353ms/step - accuracy: 0.0596 - loss: 2.6494 - val_accuracy: 0.1152 - val_loss: 0.1110 - learning_rate: 0.0010\n","Epoch 2/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 359ms/step - accuracy: 0.1150 - loss: 0.0692 - val_accuracy: 0.1176 - val_loss: 0.0131 - learning_rate: 0.0010\n","Epoch 3/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 354ms/step - accuracy: 0.1162 - loss: 0.0106 - val_accuracy: 0.1177 - val_loss: 0.0042 - learning_rate: 0.0010\n","Epoch 4/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 351ms/step - accuracy: 0.1163 - loss: 0.0035 - val_accuracy: 0.1177 - val_loss: 0.0021 - learning_rate: 0.0010\n","Epoch 5/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 359ms/step - accuracy: 0.1163 - loss: 0.0025 - val_accuracy: 0.1177 - val_loss: 0.0023 - learning_rate: 0.0010\n","Epoch 6/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 361ms/step - accuracy: 0.1163 - loss: 0.0020 - val_accuracy: 0.1177 - val_loss: 0.0014 - learning_rate: 0.0010\n","Epoch 7/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 353ms/step - accuracy: 0.1163 - loss: 0.0015 - val_accuracy: 0.1177 - val_loss: 0.0013 - learning_rate: 0.0010\n","Epoch 8/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 356ms/step - accuracy: 0.1162 - loss: 0.0038 - val_accuracy: 0.1177 - val_loss: 0.0013 - learning_rate: 0.0010\n","Epoch 9/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 359ms/step - accuracy: 0.1163 - loss: 0.0015 - val_accuracy: 0.1177 - val_loss: 0.0013 - learning_rate: 0.0010\n","Epoch 10/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 350ms/step - accuracy: 0.1163 - loss: 0.0015 - val_accuracy: 0.1177 - val_loss: 0.0012 - learning_rate: 0.0010\n","Epoch 11/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 334ms/step - accuracy: 0.1163 - loss: 0.0013 - val_accuracy: 0.1177 - val_loss: 0.0013 - learning_rate: 5.0000e-04\n","Epoch 12/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 343ms/step - accuracy: 0.1163 - loss: 0.0013 - val_accuracy: 0.1177 - val_loss: 0.0014 - learning_rate: 5.0000e-04\n","Epoch 13/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 337ms/step - accuracy: 0.1163 - loss: 0.0013 - val_accuracy: 0.1177 - val_loss: 0.0014 - learning_rate: 5.0000e-04\n","Epoch 14/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 341ms/step - accuracy: 0.1163 - loss: 0.0012 - val_accuracy: 0.1177 - val_loss: 0.0015 - learning_rate: 2.5000e-04\n","Epoch 15/50\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 337ms/step - accuracy: 0.1163 - loss: 0.0012 - val_accuracy: 0.1177 - val_loss: 0.0016 - learning_rate: 2.5000e-04\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Model and tokenizers exported successfully!\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# ============================\n","# Configuración de parámetros\n","# ============================\n","latent_dim = 256  # Reducido para menor consumo de memoria\n","num_samples = 10000  # Número máximo de muestras\n","max_input_length = 20  # Reducido para mejorar eficiencia\n","max_output_length = 200\n","\n","# Leer el archivo TSV en español con pandas\n","file_path_es_algo = \"massive_dataset_es.tsv\"\n","data_es_algo = pd.read_csv(file_path_es_algo, sep=\"\\t\")\n","\n","# Leer el archivo TSV en inglés con pandas\n","file_path_en_algo = \"massive_dataset_en.tsv\"\n","data_en_algo = pd.read_csv(file_path_en_algo, sep=\"\\t\")\n","\n","# Extraer columnas \"Question\" y \"Answer\"\n","input_texts_es_algo = data_es_algo[\"Question\"].tolist()\n","output_texts_es_algo = [\"<start> \" + str(answer_es) + \" <end>\" for answer_es in data_es_algo[\"Answer\"].tolist()]\n","\n","input_texts_en_algo = data_en_algo[\"Question\"].tolist()\n","output_texts_en_algo = [\"<start> \" + str(answer_en) + \" <end>\" for answer_en in data_en_algo[\"Answer\"].tolist()]\n","\n","# Unificación de datasets\n","input_texts = input_texts_es_algo + input_texts_en_algo\n","output_texts = output_texts_es_algo + output_texts_en_algo\n","\n","# ========================\n","# Preprocesamiento de datos\n","# ========================\n","# Tokenización de las secuencias\n","input_tokenizer = Tokenizer()\n","output_tokenizer = Tokenizer(filters=\"\")\n","\n","input_tokenizer.fit_on_texts(input_texts)\n","output_tokenizer.fit_on_texts(output_texts)\n","\n","input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n","output_sequences = output_tokenizer.texts_to_sequences(output_texts)\n","\n","# Agregar padding para las secuencias\n","encoder_input_data = pad_sequences(input_sequences, maxlen=max_input_length, padding=\"post\")\n","decoder_input_data = pad_sequences([seq[:-1] for seq in output_sequences], maxlen=max_output_length, padding=\"post\")\n","decoder_target_data = pad_sequences([seq[1:] for seq in output_sequences], maxlen=max_output_length, padding=\"post\")\n","\n","# Dividir los datos en entrenamiento y validación\n","encoder_train, encoder_val, decoder_input_train, decoder_input_val, decoder_target_train, decoder_target_val = train_test_split(\n","    encoder_input_data, decoder_input_data, decoder_target_data, test_size=0.2, random_state=42\n",")\n","\n","# ===================\n","# Construcción del modelo\n","# ===================\n","# Encoder\n","encoder_inputs = Input(shape=(None,), dtype=\"int32\")\n","encoder_embedding = tf.keras.layers.Embedding(input_dim=len(input_tokenizer.word_index) + 1,\n","                                               output_dim=latent_dim,\n","                                               mask_zero=True)(encoder_inputs)\n","encoder_lstm = LSTM(latent_dim, return_state=True)\n","_, state_h, state_c = encoder_lstm(encoder_embedding)\n","encoder_states = [state_h, state_c]\n","\n","# Decoder\n","decoder_inputs = Input(shape=(None,), dtype=\"int32\")\n","decoder_embedding = tf.keras.layers.Embedding(input_dim=len(output_tokenizer.word_index) + 1,\n","                                               output_dim=latent_dim,\n","                                               mask_zero=True)(decoder_inputs)\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n","decoder_dense = Dense(len(output_tokenizer.word_index) + 1, activation=\"softmax\")\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Modelo Seq2Seq\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Compilar el modelo\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","# Resumen del modelo\n","model.summary()\n","\n","# ========================\n","# Generador de datos\n","# ========================\n","def data_generator(encoder_data, decoder_input_data, decoder_target_data, batch_size):\n","    while True:\n","        for i in range(0, len(encoder_data), batch_size):\n","            yield ([encoder_data[i:i + batch_size], decoder_input_data[i:i + batch_size]],\n","                   decoder_target_data[i:i + batch_size])\n","\n","# Generadores para entrenamiento y validación\n","batch_size = 16\n","train_generator = data_generator(encoder_train, decoder_input_train, decoder_target_train, batch_size)\n","val_generator = data_generator(encoder_val, decoder_input_val, decoder_target_val, batch_size)\n","\n","def data_generator(encoder_data, decoder_input_data, decoder_target_data, batch_size):\n","    def generator():\n","        for i in range(0, len(encoder_data), batch_size):\n","            # Convert NumPy arrays to tf.int32 tensors\n","            encoder_input = tf.cast(encoder_data[i:i + batch_size], dtype=tf.int32)\n","            decoder_input = tf.cast(decoder_input_data[i:i + batch_size], dtype=tf.int32)\n","            decoder_target = tf.cast(decoder_target_data[i:i + batch_size], dtype=tf.int32)\n","\n","            # Yield data in the expected structure (tuple of tuples)\n","            yield ((encoder_input, decoder_input), decoder_target)\n","    return generator\n","\n","# Crear datasets usando tf.data.Dataset.from_generator\n","batch_size = 16\n","\n","train_dataset = tf.data.Dataset.from_generator(\n","    data_generator(encoder_train, decoder_input_train, decoder_target_train, batch_size),\n","    output_signature=(\n","        (\n","            tf.TensorSpec(shape=(None, max_input_length), dtype=tf.int32),\n","            tf.TensorSpec(shape=(None, max_output_length), dtype=tf.int32),\n","        ),\n","        tf.TensorSpec(shape=(None, max_output_length), dtype=tf.int32)\n","    )\n",").prefetch(tf.data.AUTOTUNE)\n","\n","val_dataset = tf.data.Dataset.from_generator(\n","    data_generator(encoder_val, decoder_input_val, decoder_target_val, batch_size),\n","    output_signature=(\n","        (\n","            tf.TensorSpec(shape=(None, max_input_length), dtype=tf.int32),\n","            tf.TensorSpec(shape=(None, max_output_length), dtype=tf.int32),\n","        ),\n","        tf.TensorSpec(shape=(None, max_output_length), dtype=tf.int32)\n","    )\n",").prefetch(tf.data.AUTOTUNE)\n","\n","# Entrenar el modelo usando los datasets\n","model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=50,\n","    callbacks=[\n","        EarlyStopping(patience=5, monitor=\"val_loss\"),\n","        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n","    ]\n",")\n","\n","# ===================\n","# Modelos para inferencia\n","# ===================\n","# Encoder para inferencia\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","# Decoder para inferencia\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_lstm_outputs, state_h, state_c = decoder_lstm(\n","    decoder_embedding, initial_state=decoder_states_inputs\n",")\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_lstm_outputs)\n","\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states,\n",")\n","\n","# ===================\n","# Función para decodificar secuencias\n","# ===================\n","reverse_input_word_index = dict((i, word) for word, i in input_tokenizer.word_index.items())\n","reverse_output_word_index = dict((i, word) for word, i in output_tokenizer.word_index.items())\n","\n","def decode_sequence(input_seq):\n","    states_value = encoder_model.predict(input_seq)\n","\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = output_tokenizer.word_index[\"<start>\"]\n","\n","    stop_condition = False\n","    decoded_sentence = \"\"\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = reverse_output_word_index.get(sampled_token_index, \"\")\n","\n","        decoded_sentence += \" \" + sampled_word\n","\n","        if sampled_word == \"<end>\" or len(decoded_sentence.split()) > max_output_length:\n","            stop_condition = True\n","\n","        target_seq = np.zeros((1, 1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        states_value = [h, c]\n","\n","    return decoded_sentence\n","\n","# Guardar el modelo\n","model.save(\"seq2seq_model.h5\")\n","tf.saved_model.save(model, 'tf_model')\n","\n","# Exportar tokenizadores a JSON\n","with open(\"input_tokenizer.json\", \"w\") as f:\n","    f.write(input_tokenizer.to_json())\n","\n","with open(\"output_tokenizer.json\", \"w\") as f:\n","    f.write(output_tokenizer.to_json())\n","\n","print(\"Model and tokenizers exported successfully!\")\n"]},{"cell_type":"code","source":["def chat_with_bot(input_text):\n","    \"\"\"\n","    Genera una respuesta del chatbot para un texto de entrada.\n","    \"\"\"\n","    # Convertir el texto de entrada a una secuencia indexada y aplicar padding\n","    input_seq = pad_sequences(\n","        input_tokenizer.texts_to_sequences([input_text]),\n","        maxlen=max_input_length,\n","        padding=\"post\"\n","    )\n","\n","    # Predecir los estados del encoder\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Crear la secuencia inicial del decoder (<start>)\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = output_tokenizer.word_index[\"<start>\"]\n","\n","    # Inicializar la respuesta generada\n","    stop_condition = False\n","    decoded_sentence = []\n","\n","    while not stop_condition:\n","        # Generar predicción del siguiente token\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        # Obtener el índice del token con mayor probabilidad\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = reverse_output_word_index.get(sampled_token_index, \"\")\n","\n","        # Agregar la palabra generada a la respuesta\n","        if sampled_word != \"<end>\":\n","            decoded_sentence.append(sampled_word)\n","\n","        # Condición de parada: token <end> o longitud máxima alcanzada\n","        if sampled_word == \"<end>\" or len(decoded_sentence) > max_output_length:\n","            stop_condition = True\n","\n","        # Actualizar la secuencia de entrada para el decoder\n","        target_seq = np.zeros((1, 1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        # Actualizar los estados del decoder\n","        states_value = [h, c]\n","\n","    # Retornar la respuesta generada como texto\n","    return \" \".join(decoded_sentence)\n"],"metadata":{"id":"MzhOQkA1LxNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"----\")\n","print(chat_with_bot(\"Quiero el algoritmo de la busqueda fibonacci en python.\").replace(\"\\\\n\",\"\\n\").replace(\"\\\\t\",\"\\t\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNQ7DFMXLcHp","executionInfo":{"status":"ok","timestamp":1735822179882,"user_tz":360,"elapsed":7308,"user":{"displayName":"Camilo Ernesto Sincal Sipac","userId":"00229629946990659316"}},"outputId":"629783a2-1535-4837-d72d-faa0625b6362"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["----\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","def fibonacci_search(arr, x):\n","\tfib_m2 = 0\n","\tfib_m1 = 1\n","\tfib_m = fib_m2 + fib_m1\n","\tn = len(arr)\n","\twhile fib_m < n:\n","\t\tfib_m2 = fib_m1\n","\t\tfib_m1 = fib_m\n","\t\tfib_m = fib_m2 + fib_m1\n","\toffset = -1\n","\twhile fib_m > 1:\n","\t\ti = min(offset + fib_m2, n - 1)\n","\t\tif arr[i] < x:\n","\t\t\tfib_m = fib_m1\n","\t\t\tfib_m1 = fib_m2\n","\t\t\tfib_m2 = fib_m - fib_m1\n","\t\t\toffset = i\n","\t\telif arr[i] > x:\n","\t\t\tfib_m = fib_m2\n","\t\t\tfib_m1 = fib_m1 - fib_m2\n","\t\t\tfib_m2 = fib_m - fib_m1\n","\t\telse:\n","\t\t\treturn i\n","\tif fib_m1 and arr[offset + 1] == x:\n","\t\treturn offset + 1\n","\treturn -1\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","folder_to_zip = './tf_model'\n","output_zip_file = 'tf_model.zip'\n","\n","shutil.make_archive(output_zip_file.replace('.zip', ''), 'zip', folder_to_zip)\n","\n","print(f'Carpeta comprimida exitosamente como: {output_zip_file}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pe0-s5eyPsMt","executionInfo":{"status":"ok","timestamp":1735822230367,"user_tz":360,"elapsed":1386,"user":{"displayName":"Camilo Ernesto Sincal Sipac","userId":"00229629946990659316"}},"outputId":"3c2340b0-3539-49d7-b6a6-664a43e42760"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Carpeta comprimida exitosamente como: tf_model.zip\n"]}]}]}